# Jupyter notebook with PySpark for interactive Iceberg table queries
services:
  spark-notebook:
    image: jupyter/all-spark-notebook:latest  # Multi-arch with PySpark kernel pre-registered
    container_name: spark-notebook
    environment:
      JUPYTER_ENABLE_LAB: "yes"  # Enable JupyterLab interface
      JUPYTER_TOKEN: ${JUPYTER_TOKEN}
      AWS_REGION: us-east-1
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      POLARIS_USERNAME: ${POLARIS_USERNAME}
      POLARIS_PASSWORD: ${POLARIS_PASSWORD}
      POLARIS_CATALOG_NAME: ${POLARIS_CATALOG_NAME}
    ports:
      - "8888:8888"  # Jupyter notebook interface
      - "4040:4040"  # Spark UI for monitoring jobs
    networks:
      - local-iceberg-lakehouse
    volumes:
      - ./spark-notebooks:/home/jovyan/work  # Mount local notebooks to Jupyter's work directory

networks:
  local-iceberg-lakehouse:
    name: local-iceberg-lakehouse